# The CLunch talks can be added to this file. They will appear on the website
# in the order that they appear here, so they should be listed in
# reverse-chronological order.
#
# This should contain speakers for the current semester (that have already spoken, upcoming speakers
# go in future_clunch.yml), and previous semester.
#
# Here is the template for an entry:
#
# - speaker: Name of the Speaker
#   url: http://speakers-website.com
#   affiliation: University Name
#   date: June 26, 2019
#   title: The talk of the title goes here.
#   abstract: The abstract of the talk will go here.
- speaker: Niranjan Balasubramanian
  url: https://www3.cs.stonybrook.edu/~niranjan/
  img: assets/img/clunch/niranjan-2015.jpg
  affiliation: Stony Brook University
  date: March 6th, 2023
  title: "What ails multi-step reasoning and how to fix it."
  abstract: 'Multi-step reasoning has seen much empirical progress on many datasets recently, especially in Question Answering. However, training and evaluating on typical crowdsourced datasets is problematic because of the potential for shortcut reasoning based on artifacts. What can we do about this? In this three part talk, I will first show how we can formalize and measure disconnected reasoning, a type of bad multihop reasoning. I will then discuss how we can construct new datasets using a bottom-up construction process,  which allows us to better control for desired properties in the resulting dataset. In the third part, I will briefly present how synthetically generated data can be used to teach a broad range of multihop skills in a reliable manner and how to improve reliable multi-step reasoning in open-domain QA settings.'
  
- speaker: Graham Neubig
  url: http://www.phontron.com/
  img: assets/img/clunch/graham_neubig.jpeg
  affiliation: Carnegie Mellon University (Language Technology Institute)
  date: March 1st, 2023
  title: "Is My NLP Model Working? The Answer is Harder Than You Think"
  abstract: 'As natural language processing now permeates many different applications, its practical use is unquestionable. However, at the same time NLP is still imperfect, and errors cause everything from minor inconveniences to major PR disasters. Better understanding when our NLP models work and when they fail is critical to the efficient and reliable use of NLP in real-world scenarios. So how can we do so? In this talk I will discuss two issues: automatic evaluation of generated text, and automatic fine-grained analysis of NLP system results, which are some first steps towards a science of NLP model evaluation.'

- speaker: Alan Ritter
  url: http://aritter.github.io
  img: assets/img/clunch/alan_ritter.JPG
  affiliation: Georgia Tech
  date: February 24th, 2023
  title: "Towards Cost Efficient Use of Pre-Trained Language Models"
  abstract: 'Large language models are leading to breakthroughs in a variety of applications, from information extraction systems that are accurate and robust, to human-like conversational assistants.  In this talk I will analyze when the benefits of training a new model outweigh the computational costs, in the context of domain adaptation.  Conventional wisdom holds that data annotation is expensive, so computational methods that leverage freely available unlabeled data can present an economical alternative when adapting to a new domain.  The talk will examine this assumption in the context of pretraining-based domain adaptation, which requires significant GPU/TPU resources for each new domain.  We frame domain adaptation as a consumer choice problem: given a fixed budget, what combination of annotation and pre-training lead to maximum utility?  In the second part of the talk, I will discuss recent work on in-context learning for anaphora resolution.  I will show that resolving anaphora in scientific protocols is a challenging task for in-context learning, then present a new method, MICE (Mixtures of In-Context Experts) and demonstrate how it can accurately resolve multiple-antecedent anaphora in paragraphs describing chemical synthesis procedures.  MICE enables accurate few-shot anaphora resolution by ensembling hundreds of prompts that are created from only a handful of training examples.  Finally, I will discuss applications of NLP on chemical synthesis protocols and show a demo of a system that can help chemists more efficiently find experimental details described in the literature.'
  
- speaker: Julian Michael
  url: https://julianmichael.org
  img: assets/img/clunch/julian_michael.jpg
  affiliation: NYU
  date: February 15th, 2023
  title: "What Do NLP Researchers Believe? Results of the NLP Community Metasurvey"
  abstract: 'I will present the results of the NLP Community Metasurvey (https://nlpsurvey.net). This was a questionnaire that we ran from May to June 2022 which elicited the opinions of NLP researchers on controversial issues, including industry influence in the field, concerns about AGI, and ethics. Our results put concrete numbers to several controversies. For example, respondents are split almost exactly in half on questions about: the importance of artificial general intelligence, whether language models understand language, and the necessity of linguistic structure and inductive bias for solving NLP problems. In addition, the survey posed "meta-questions," asking respondents to predict the distribution of survey responses. This allows us not only to gain insight on the spectrum of beliefs held by NLP researchers, but also to uncover false sociological beliefs where the community’s predictions don’t match reality. We find such mismatches on a wide range of issues. Among other results, the community greatly overestimates its own belief in the usefulness of benchmarks and the potential for scaling to solve real-world problems, while underestimating its own belief in the importance of linguistic structure, inductive bias, and interdisciplinary science. Our hope is that this can provide context for the NLP research community to have more informed and self-aware discussions of these complex issues. In this talk, I will walk through our results and open the floor for such a discussion.'

- speaker: Karl Stratos
  url: https://karlstratos.com
  img: assets/img/clunch/karl_stratos.png
  affiliation: Rutgers CS
  date: February 1st, 2023
  title: "Retrieval-Augmented Models for Natural Language Processing"
  abstract: 'Prompting large pretrained language models has been enormously successful in solving a wide class of natural language tasks. In this approach, a task is formatted in some natural language template to "prompt" the model to generate the correct answer (e.g., "Q: Why is the sky blue? A: "). While surprisingly effective, it often generates false and unverifiable claims, limiting real-world applications. In this talk, I will advocate an alternative approach based on retrieval. Instead of naively generating answers, the model must first retrieve a piece of evidence from a knowledge base (e.g., Wikipedia). By having an explicit knowledge retrieval step, the model is forced to return factually accurate and verifiable claims. It can also use a new knowledge base at test time, thus is capable of zero-shot learning. I will focus on the task of entity retrieval and linking. I will first present a technique based on hard negative mining to make entity retrieval more robust (NAACL 2021). I will then build on the retrieval framework to present a novel paradigm for entity linking (ICLR 2022).'
  
- speaker: Gail Weiss
  url: https://gailweiss.github.io
  img: assets/img/clunch/gail_weiss.jpeg
  affiliation: EPFL
  date: January 25, 2023
  title: "Thinking Like Transformers"
  abstract: Transformers - the purely attention based NN architecture - have emerged as a powerful tool in sequence processing. But how does a transformer think? When we discuss the computational power of RNNs, or consider a problem that they have solved, it is easy for us to think in terms of automata and their variants (such as counter machines and pushdown automata). But when it comes to transformers, no such intuitive model is available.
    In this talk I will present a programming language, RASP (Restricted Access Sequence Processing), which we hope will serve the same purpose for transformers as finite state machines do for RNNs. In particular, we will identify the base computations of a transformer and abstract them into a small number of primitives, which are composed into a small programming language. We will go through some example programs in the language, and discuss how a given RASP program relates to the transformer architecture.
