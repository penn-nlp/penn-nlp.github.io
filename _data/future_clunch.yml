# Upcoming CLunch talks can be added to this file. They will appear on the website
# in the order that they appear here, so they should be listed in
# reverse-chronological order.
#
# This should contain upcoming speakers for the current semester.
#
# Here is the template for an entry:
#
# - speaker: Name of the Speaker
#   url: http://speakers-website.com
#   affiliation: University Name
#   date: June 26, 2019
#   title: The talk of the title goes here.
#   abstract: The abstract of the talk will go here.

- speaker: Li "Harry" Zhang
  url: https://zharry29.github.io/
  affiliation: Drexel University
  date: February 17, 2025
  img: assets/img/clunch/harry_zhang.jpg
  title: Executable and Trustworthy Planning with Large Language Models
  abstract: While large language models (LLM) can provide decent instructions, they are far from able to come up an executable and trustworthy plan for a particular user or agent, grounding to their specific situation and needs. To address this, I advocate for the methodology of using LLM as a code generator to create a formal representation of the planning environment. In conjunction with tools in classical AI planning, a plan can be found deterministically and faithfully. In this talk, I will discuss two strands of efforts. The first tackles fully-observed planning domains, where the model is given complete information and must propose a complete plan that satisfies given constraints. The second tackles partially-observed planning domains, where the model makes partial observations about the environment, propose partial plans, and iteratively acquire knowledge to complete a task. In both settings, we show that state-of-the-art models like DeepSeek-R1 and gpt-4o are heavily challenged by even the simplest tasks like rearranging or looking for objects. When prompted to generate the planning domain definition language (PDDL) input into a solver, LLMs outperform generating the plans directly. Even so, both syntactic and semantic errors point to LLMs' weakened ability to generate formal representations, especially when the language or domain is underrepresented in their pre-training.

- speaker: Joel Tetreault
  url: https://www.cs.rochester.edu/~tetreaul/
  affiliation: Dataminr
  date: February 24, 2025
  img: assets/img/clunch/joel_tetreault.jpg

- speaker: Parisa Kordjamshidi
  url: https://www.cse.msu.edu/~kordjams/
  affiliation: Michigan State University
  date: March 03, 2025
  img: assets/img/clunch/parisa_kordjamshidi.jpg

- speaker: Sachin Kumar
  url: https://sites.google.com/view/sachinkumar
  affiliation: Ohio State University
  date: March 17, 2025
  img: assets/img/clunch/sachin_kumar.jpg

- speaker: Wei Xu
  url: https://cocoxu.github.io/
  affiliation: Georgia Institute of Technology
  date: March 24, 2025
  img: assets/img/clunch/wei_xu.jpg

- speaker: Jesse Thomason
  url: https://jessethomason.com/
  affiliation: University of Southern California
  date: March 31, 2025
  img: assets/img/clunch/jesse_thomason.jpg

- speaker: Leena Mathur
  url: https://l-mathur.github.io/
  affiliation: Carnegie Mellon University
  date: April 07, 2025
  img: assets/img/clunch/leena_mathur.jpg

- speaker: Yoav Artzi
  url: https://yoavartzi.com/
  affiliation: Cornell University
  date: April 14, 2025
  img: assets/img/clunch/yoav_artzi.jpg

- speaker: Daniel Khashabi
  url: https://danielkhashabi.com/
  affiliation: Johns Hopkins University
  date: April 21, 2025
  img: assets/img/clunch/daniel_khashabi.jpg

- speaker: Deen Freelon
  url: https://dfreelon.org/
  affiliation: University of Pennsylvania
  date: April 28, 2025
  img: assets/img/clunch/deen_freelon.jpg