# Upcoming CLunch talks can be added to this file. They will appear on the website
# in the order that they appear here, so they should be listed in
# reverse-chronological order.
#
# This should contain upcoming speakers for the current semester.
#
# Here is the template for an entry:
#
# - speaker: Name of the Speaker
#   url: http://speakers-website.com
#   affiliation: University Name
#   date: June 26, 2019
#   title: The talk of the title goes here.
#   abstract: The abstract of the talk will go here.

- speaker: Emma Strubell
  url: https://strubell.github.io/
  affiliation: Carnegie Mellon University
  date: December 09, 2024
  title: TBD
  abstract: TBD

- speaker: Colin Raffel
  url: https://colinraffel.com/
  affiliation: University of Toronto
  date: December 02, 2024
  title: TBD
  abstract: TBD

- speaker: Julia Mendelsohn
  url: https://juliamendelsohn.github.io/
  affiliation: University of Michigan
  date: November 25, 2024
  title: TBD
  abstract: TBD

- speaker: Luca Soldaini
  url: https://soldaini.net/
  affiliation: Allen Institute for AI
  date: November 11, 2024
  title: TBD
  abstract: TBD

- speaker: Tomer Wolfson
  url: https://tomerwolgithub.github.io/
  affiliation: University of Pennsylvania
  date: November 04, 2024
  title: TBD
  abstract: TBD

- speaker: Valerie Chen
  url: https://valeriechen.github.io/
  affiliation: Carnegie Mellon University
  date: October 28, 2024
  title: TBD
  abstract: TBD

- speaker: Tanya Goyal
  url: https://tagoyal.github.io/
  affiliation: Cornell University
  date: October 21, 2024
  title: TBD
  abstract: TBD

- speaker: John Hewitt
  url: https://nlp.stanford.edu/~johnhew/
  affiliation: Stanford University
  date: October 14, 2024
  title: TBD
  abstract: TBD

- speaker: Yejin Choi
  url: https://homes.cs.washington.edu/~yejin/
  affiliation: University of Washington
  date: October 07, 2024
  title: TBD
  abstract: TBD

- speaker: Harsh Trivedi
  url: https://harshtrivedi.me/
  affiliation: Stony Brook University
  date: September 30, 2024
  title: TBD
  abstract: TBD

- speaker: Ajay Patel
  url: https://ajayp.app/
  affiliation: University of Pennsylvania
  date: September 16, 2024
  title: "DataDreamer: Synthetic Data Generation and Reproducible LLM Workflows"
  abstract: "Large language models (LLMs) have become an essential tool for NLP researchers in a wide range of tasks. Many now rely on LLMs for synthetic data generation, task evaluation, fine-tuning, and other model-in-the-loop workflows. However, challenges arise due to their scale, closed-source nature, and the lack of standardized tooling, which can hinder open science and reproducibility. In this talk, we present DataDreamer, an open-source Python library designed to help researchers implement LLM workflows more easily. DataDreamer also promotes best practices that support open science and improve reproducibility in research."

- speaker: Artemis Panagopoulou
  url: https://artemisp.github.io/
  affiliation: University of Pennsylvania
  date: September 16, 2024
  title: "Advancing Multimodal AI: Integrating Modalities, Tackling Complex Challenges, and Enhancing Interpretability"
  abstract: "Advancing AI systems that understand and integrate multiple modalities—such as images, language, audio, video, and 3D—has significant implications for real-world applications. A major challenge lies in developing AI models that can efficiently process diverse modalities while providing transparent and interpretable decision-making. This talk will highlight recent contributions, including X-InstructBLIP, a framework for aligning multimodal representations with language models for cross-modal reasoning; studies on bistable images that reveal how AI models interpret visual ambiguity; and ongoing work on visual unit testing to ensure robust, and interpretable multimodal reasoning."

- speaker: Xingyu Fu
  url: https://zeyofu.github.io/
  affiliation: University of Pennsylvania
  date: September 16, 2024
  title: "Better Evaluations for Multimodal Generative Models"
  abstract: "Multimodal generative models such as GPT-4o and DALL-E 3 are being developed at a rapid pace. While these models have incredible new abilities, we still mostly follow the same old paradigms when it comes to evaluating the language or images that these models produce. Consequently, these models' potential is constrained by outdated evaluation criteria. In this talk, we will introduce two new benchmarks: (1) BLINK, designed to assess core visual perception abilities that are not addressed by existing benchmarks for multimodal large language models; and (2) Commonsense-T2I, which tests whether the generated images align with real-life commonsense. Our findings show that current multimodal generative models perform significantly worse than humans on both benchmarks, highlighting potential pathways for future improvements."

- speaker: Subbarao Kambhampati
  url: https://rakaposhi.eas.asu.edu/
  affiliation: Arizona State University
  date: September 9, 2024
  title: "Can LLMs Reason and Plan?"
  abstract: "Large Language Models (LLMs) are on track to reverse what seemed like an inexorable shift of AI from explicit to tacit knowledge tasks. Trained as they are on everything ever written on the web, LLMs exhibit “approximate omniscience”–they can provide answers to all sorts of queries, but with nary a guarantee. This could herald a new era for knowledge-based AI systems–with LLMs taking the role of (blowhard?) experts. But first, we have to stop confusing the impressive style/form of the generated knowledge for correct/factual content, and resist the temptation to ascribe reasoning, planning, self-critiquing etc. powers to approximate retrieval by these n-gram models on steroids. We have to focus instead on LLM-Modulo techniques that complement the unfettered idea generation of LLMs with careful vetting by model-based verifiers (the models underlying which themselves can be teased out from LLMs in semi-automated fashion). In this talk, I will reify this vision and attendant caveats in the context of our ongoing work on understanding the role of LLMs in planning tasks."
